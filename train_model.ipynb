{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55c54eb-accc-49fe-ad1f-29b83fddc3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vinaybabujatla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Download NLTK stopwords (if needed)\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792707af-a220-42a0-b326-d48606f8f4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>mostly-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement        label\n",
       "0  Says the Annies List political group supports ...        false\n",
       "1  When did the decline of coal start? It started...    half-true\n",
       "2  Hillary Clinton agrees with John McCain \"by vo...  mostly-true\n",
       "3  Health care reform legislation is likely to ma...        false\n",
       "4  The economic turnaround started at the end of ...    half-true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset path (adjust as needed)\n",
    "dataset_path = \"D:/nagababujatla/FakeNewsDetection/liar/\"\n",
    "\n",
    "# Load LIAR dataset files (assumes .tsv files)\n",
    "train_df = pd.read_csv(dataset_path + \"train.tsv\", sep=\"\\t\", header=None)\n",
    "valid_df = pd.read_csv(dataset_path + \"valid.tsv\", sep=\"\\t\", header=None)\n",
    "test_df  = pd.read_csv(dataset_path + \"test.tsv\", sep=\"\\t\", header=None)\n",
    "\n",
    "# Define column names based on LIAR dataset structure\n",
    "column_names = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\", \"party\", \n",
    "                \"barely_true\", \"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\", \"context\"]\n",
    "\n",
    "# Assign column names\n",
    "train_df.columns = column_names\n",
    "valid_df.columns = column_names\n",
    "test_df.columns = column_names\n",
    "\n",
    "# Keep only the necessary columns: 'statement' and 'label'\n",
    "train_df = train_df[[\"statement\", \"label\"]]\n",
    "valid_df = valid_df[[\"statement\", \"label\"]]\n",
    "test_df  = test_df[[\"statement\", \"label\"]]\n",
    "\n",
    "# Display the first few rows of the training set\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c980cbc4-d028-4b1d-a874-bd40b455f94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  label\n",
       "0  Says the Annies List political group supports ...    0.0\n",
       "1  When did the decline of coal start? It started...    1.0\n",
       "2  Hillary Clinton agrees with John McCain \"by vo...    1.0\n",
       "3  Health care reform legislation is likely to ma...    0.0\n",
       "4  The economic turnaround started at the end of ...    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define label mapping: \"true\" & \"mostly-true\" as Real (1); the rest as Fake (0)\n",
    "label_mapping = {\n",
    "    \"true\": 1,\n",
    "    \"mostly-true\": 1,\n",
    "    \"half-true\": 1,\n",
    "    \"barely-true\": 0,\n",
    "    \"false\": 0,\n",
    "    \"pants-on-fire\": 0\n",
    "}\n",
    "\n",
    "# Apply mapping to all datasets\n",
    "train_df[\"label\"] = train_df[\"label\"].map(label_mapping)\n",
    "valid_df[\"label\"] = valid_df[\"label\"].map(label_mapping)\n",
    "test_df[\"label\"]  = test_df[\"label\"].map(label_mapping)\n",
    "\n",
    "# Drop any rows with missing values (if any)\n",
    "train_df.dropna(inplace=True)\n",
    "valid_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# Check the updated training data\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9663d748-141f-4f5c-b34c-c3dbb09f06a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinaybabujatla\\AppData\\Local\\anaconda3\\envs\\tinybert2\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at D:/nagababujatla/FakeNewsDetection/TinyBERT_General_4L_312D/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the local TinyBERT model path (adjust as needed)\n",
    "tinybert_path = \"D:/nagababujatla/FakeNewsDetection/TinyBERT_General_4L_312D/\"\n",
    "\n",
    "# Load TinyBERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(tinybert_path)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    tinybert_path, \n",
    "    num_labels=2,\n",
    "    problem_type=\"single_label_classification\"  # ✅ Force CrossEntropyLoss (correct for binary classification)\n",
    ")\n",
    "\n",
    "# Extract text from dataframes\n",
    "train_texts = train_df[\"statement\"].tolist()\n",
    "valid_texts = valid_df[\"statement\"].tolist()\n",
    "test_texts  = test_df[\"statement\"].tolist()\n",
    "\n",
    "# Tokenize texts (with truncation and padding)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=128)\n",
    "test_encodings  = tokenizer(test_texts,  truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a7f485-95c2-4eba-b35e-a4b85ea48b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real News Count: 5752\n",
      "Fake News Count: 3649\n"
     ]
    }
   ],
   "source": [
    "print(\"Real News Count:\", sum(train_df[\"label\"] == 1))\n",
    "print(\"Fake News Count:\", sum(train_df[\"label\"] == 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d16106a6-818d-45ea-b18a-eb413d79754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"labels\": train_df[\"label\"].astype(int).tolist()  # ✅ Ensure integer labels\n",
    "})\n",
    "\n",
    "valid_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": valid_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": valid_encodings[\"attention_mask\"],\n",
    "    \"labels\": valid_df[\"label\"].astype(int).tolist()\n",
    "})\n",
    "\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"labels\": torch.tensor(test_df[\"label\"].astype(int).tolist(), dtype=torch.long).tolist(),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1c7b12-8f6e-4c4f-8051-ed65eba909b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,  # ⬆️ Increase to 20\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a36ee76-7621-4a0c-9ac3-bf16c0b21da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"results/\", ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f91bf5-b4d5-4789-93f8-fd97847f41fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='169' max='1764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 169/1764 02:20 < 22:18, 1.19 it/s, Epoch 0.29/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset\n",
    ")\n",
    "\n",
    "# Begin training TinyBERT\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d4a0f-76d8-4d06-a468-35868ab42f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6278033-9838-49ef-8755-cd4bdab81832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Evaluation Results: {'eval_loss': 0.7235797047615051, 'eval_runtime': 23.4364, 'eval_samples_per_second': 50.136, 'eval_steps_per_second': 3.157, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate(test_dataset)\n",
    "print(\"Test Evaluation Results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b948ddb-27d1-4d36-9070-9e1b2bd57059",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Get raw model predictions\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(test_dataset)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extract logits (raw output before softmax)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m logits \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mpredictions\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get raw model predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Extract logits (raw output before softmax)\n",
    "logits = predictions.predictions\n",
    "\n",
    "# Convert logits to predicted labels (argmax selects the highest probability class)\n",
    "predicted_labels = np.argmax(logits, axis=1)\n",
    "\n",
    "# Get actual labels from test dataset\n",
    "true_labels = test_df[\"label\"].tolist()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print detailed classification report (Precision, Recall, F1-score)\n",
    "print(classification_report(true_labels, predicted_labels, target_names=[\"Fake News\", \"Real News\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e6bfc-dfde-4328-87a8-f2d7525ce69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9b49fb16-d408-4816-9864-28f4a4c67c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:/nagababujatla/FakeNewsDetection/fine_tuned_tinybert\\\\tokenizer_config.json',\n",
       " 'D:/nagababujatla/FakeNewsDetection/fine_tuned_tinybert\\\\special_tokens_map.json',\n",
       " 'D:/nagababujatla/FakeNewsDetection/fine_tuned_tinybert\\\\vocab.txt',\n",
       " 'D:/nagababujatla/FakeNewsDetection/fine_tuned_tinybert\\\\added_tokens.json')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"D:/nagababujatla/FakeNewsDetection/fine_tuned_tinybert\")\n",
    "tokenizer.save_pretrained(\"D:/nagababujatla/FakeNewsDetection/fine_tuned_tinybert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "43862b45-df36-4cdc-a401-1d86678b7be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News\n",
      "Real News\n"
     ]
    }
   ],
   "source": [
    "def predict_fixed(statement):\n",
    "    inputs = tokenizer(statement, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Swap prediction mapping\n",
    "    return \"Fake News\" if prediction == 0 else \"Real News\"\n",
    "\n",
    "# Test with swapped mapping\n",
    "print(predict_fixed(\"You have won a gift, click on this link!\"))\n",
    "print(predict_fixed(\"Sun rises in the East.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e45962c6-df42-49ff-b2f0-5b5b111fcc74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The government has approved a new economic policy.\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: NASA has confirmed the discovery of a new planet.\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Click here to claim your free iPhone now!\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: COVID-19 vaccines are effective and safe.\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Breaking: The president has resigned amid corruption charges.\n",
      "Prediction: Real News\n",
      "\n",
      "Input: Congratulations! You've won $1,000,000! Claim now!\n",
      "Prediction: Real News\n",
      "\n",
      "Input: Climate change is causing rising sea levels.\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: A celebrity was spotted using this secret weight-loss pill!\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Aliens have been found in the Amazon rainforest!\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Stock market sees a 10% rise after positive economic reports.\n",
      "Prediction: Real News\n",
      "\n",
      "Input: This miracle cure can remove all diseases!\n",
      "Prediction: Real News\n",
      "\n",
      "Input: Scientists discover a new species of dinosaur in Argentina.\n",
      "Prediction: Real News\n",
      "\n",
      "Input: Lottery winner reveals the secret trick to winning!\n",
      "Prediction: Real News\n",
      "\n",
      "Input: Fake news alert: A dangerous email scam is going around!\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Sports: The national team wins the championship!\n",
      "Prediction: Real News\n",
      "\n",
      "Input: Experts warn about the rise of misinformation on social media.\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: A man claims he traveled through time and met his future self!\n",
      "Prediction: Real News\n",
      "\n",
      "Input: The central bank announces a new interest rate hike.\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Shocking! A woman finds gold hidden in her backyard!\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: New study finds that daily exercise improves mental health.\n",
      "Prediction: Real News\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_statements = [\n",
    "    \"The government has approved a new economic policy.\",  # Real News\n",
    "    \"NASA has confirmed the discovery of a new planet.\",  # Real News\n",
    "    \"Click here to claim your free iPhone now!\",  # Fake News\n",
    "    \"COVID-19 vaccines are effective and safe.\",  # Real News\n",
    "    \"Breaking: The president has resigned amid corruption charges.\",  # Real News\n",
    "    \"Congratulations! You've won $1,000,000! Claim now!\",  # Fake News\n",
    "    \"Climate change is causing rising sea levels.\",  # Real News\n",
    "    \"A celebrity was spotted using this secret weight-loss pill!\",  # Fake News\n",
    "    \"Aliens have been found in the Amazon rainforest!\",  # Fake News\n",
    "    \"Stock market sees a 10% rise after positive economic reports.\",  # Real News\n",
    "    \"This miracle cure can remove all diseases!\",  # Fake News\n",
    "    \"Scientists discover a new species of dinosaur in Argentina.\",  # Real News\n",
    "    \"Lottery winner reveals the secret trick to winning!\",  # Fake News\n",
    "    \"Fake news alert: A dangerous email scam is going around!\",  # Fake News\n",
    "    \"Sports: The national team wins the championship!\",  # Real News\n",
    "    \"Experts warn about the rise of misinformation on social media.\",  # Real News\n",
    "    \"A man claims he traveled through time and met his future self!\",  # Fake News\n",
    "    \"The central bank announces a new interest rate hike.\",  # Real News\n",
    "    \"Shocking! A woman finds gold hidden in her backyard!\",  # Fake News\n",
    "    \"New study finds that daily exercise improves mental health.\",  # Real News\n",
    "]\n",
    "\n",
    "# Run predictions\n",
    "for statement in test_statements:\n",
    "    print(f\"Input: {statement}\")\n",
    "    print(f\"Prediction: {predict_fixed(statement)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fefec91-dbab-4db5-a8ce-df94d41b7d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The government has approved a new economic policy.\n",
      "Logits: tensor([[ 0.7740, -0.7078]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8148, 0.1852]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: NASA has confirmed the discovery of a new planet.\n",
      "Logits: tensor([[ 0.9731, -0.9009]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8669, 0.1331]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Click here to claim your free iPhone now!\n",
      "Logits: tensor([[ 1.0024, -0.9274]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8732, 0.1268]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: COVID-19 vaccines are effective and safe.\n",
      "Logits: tensor([[ 0.9515, -0.8805]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8620, 0.1380]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Breaking: The president has resigned amid corruption charges.\n",
      "Logits: tensor([[ 0.2124, -0.1703]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.5945, 0.4055]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Congratulations! You've won $1,000,000! Claim now!\n",
      "Logits: tensor([[0.0318, 0.0021]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.5074, 0.4926]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Climate change is causing rising sea levels.\n",
      "Logits: tensor([[ 0.8979, -0.8226]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8482, 0.1518]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: A celebrity was spotted using this secret weight-loss pill!\n",
      "Logits: tensor([[ 0.8188, -0.7491]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8275, 0.1725]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Aliens have been found in the Amazon rainforest!\n",
      "Logits: tensor([[ 0.8806, -0.8161]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8451, 0.1549]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Stock market sees a 10% rise after positive economic reports.\n",
      "Logits: tensor([[-0.2127,  0.2190]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.3937, 0.6063]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 1\n",
      "Prediction: Real News\n",
      "\n",
      "Input: This miracle cure can remove all diseases!\n",
      "Logits: tensor([[ 0.8396, -0.7649]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8326, 0.1674]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Scientists discover a new species of dinosaur in Argentina.\n",
      "Logits: tensor([[ 0.8304, -0.7674]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8317, 0.1683]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Lottery winner reveals the secret trick to winning!\n",
      "Logits: tensor([[ 0.8182, -0.7490]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8274, 0.1726]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Fake news alert: A dangerous email scam is going around!\n",
      "Logits: tensor([[ 1.0771, -1.0004]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8887, 0.1113]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Sports: The national team wins the championship!\n",
      "Logits: tensor([[-0.4197,  0.4138]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.3029, 0.6971]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 1\n",
      "Prediction: Real News\n",
      "\n",
      "Input: Experts warn about the rise of misinformation on social media.\n",
      "Logits: tensor([[ 0.7480, -0.6837]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8072, 0.1928]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: A man claims he traveled through time and met his future self!\n",
      "Logits: tensor([[ 0.5101, -0.4528]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.7237, 0.2763]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: The central bank announces a new interest rate hike.\n",
      "Logits: tensor([[ 0.9702, -0.8978]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8662, 0.1338]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: Shocking! A woman finds gold hidden in her backyard!\n",
      "Logits: tensor([[ 0.9669, -0.8906]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.8650, 0.1350]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n",
      "Input: New study finds that daily exercise improves mental health.\n",
      "Logits: tensor([[ 0.5776, -0.5227]], grad_fn=<AddmmBackward0>)\n",
      "Probabilities: tensor([[0.7503, 0.2497]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 0\n",
      "Prediction: Fake News\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_fixed(statement):\n",
    "    inputs = tokenizer(statement, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    \n",
    "    # Adjust threshold: Instead of argmax, use a probability threshold\n",
    "    prediction = 1 if probs[0][1] > 0.6 else 0  # Adjust the 0.6 threshold as needed\n",
    "\n",
    "    print(f\"Logits: {logits}\")\n",
    "    print(f\"Probabilities: {probs}\")\n",
    "    print(f\"Predicted Class: {prediction}\")\n",
    "\n",
    "    return \"Fake News\" if prediction == 0 else \"Real News\"\n",
    "\n",
    "# Run new tests\n",
    "for statement in test_statements:\n",
    "    print(f\"Input: {statement}\")\n",
    "    print(f\"Prediction: {predict_fixed(statement)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e6906-ff7c-4807-8e74-664afcc4baf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f90af-4f15-4d04-9b6e-793c793c71d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
